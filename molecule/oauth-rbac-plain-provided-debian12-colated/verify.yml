---
### Validates Metrics reporter without C3.
### Validates that secrets protection is enabled on correct properties.
### Validates truststore is present across components.
### Validates that Java 17 is in Use
### Validates LDAP authentication

- name: Verify Java
  hosts: all,!ldap_server,!kafka_controller_migration,!oauth_server  #Workaround to skip the task in migration test, need to remove in CP 8.0
  gather_facts: false
  tasks:
    - name: Get Java Version
      shell: java -version
      register: version_output

    - name: Assert Java Version is 17
      assert:
        that:
          - version_output.stderr_lines[0] | regex_search("17\.0\.")
        fail_msg: "Current Java Version is: {{version_output.stderr_lines[0]}}. Verify again"
        quiet: true

- name: Verify - kafka_controller
  hosts: kafka_controller
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/controller/server.properties
        property: ssl.truststore.location
        expected_value: /var/ssl/private/kafka_controller.truststore.jks

- name: Verify - kafka_broker
  hosts: kafka_broker
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: metric.reporters
        expected_value: io.confluent.metrics.reporter.ConfluentMetricsReporter

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: ldap.java.naming.security.credentials
        expected_value: ${securepass:/var/ssl/private/kafka-broker-security.properties:server.properties/ldap.java.naming.security.credentials}

- name: Verify - schema_registry
  hosts: schema_registry
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/schema-registry/schema-registry.properties
        property: ssl.truststore.location
        expected_value: /var/ssl/private/schema_registry.truststore.jks

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/schema-registry/schema-registry.properties
        property: confluent.metadata.http.auth.credentials.provider
        expected_value: OAUTHBEARER

- name: Verify - kafka_rest
  hosts: kafka_rest
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka-rest/kafka-rest.properties
        property: ssl.truststore.location
        expected_value: /var/ssl/private/kafka_rest.truststore.jks

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka-rest/kafka-rest.properties
        property: producer.interceptor.classes
        expected_value: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka-rest/kafka-rest.properties
        property: confluent.metadata.basic.auth.user.info
        expected_value: ${securepass:/var/ssl/private/kafka-rest-security.properties:kafka-rest.properties/confluent.metadata.basic.auth.user.info}

- name: Verify - kafka_connect
  hosts: kafka_connect
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/connect-distributed.properties
        property: ssl.truststore.location
        expected_value: /var/ssl/private/kafka_connect.truststore.jks

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/connect-distributed.properties
        property: producer.interceptor.classes
        expected_value: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/connect-distributed.properties
        property: confluent.metadata.http.auth.credentials.provider
        expected_value: OAUTHBEARER

    - name: Get Connectors on connect cluster1
      uri:
        url: "https://kafka-connect1:8083/connectors"
        status_code: 200
        validate_certs: false
        url_username: "kafka_connect"
        url_password: "password"
      register: connectors1

    - debug:
        msg: "{{connectors1.json}}"

    - import_role:
        name: confluent.platform.common
        tasks_from: get_authorization_token.yml
      vars:
        oauth: "{{ kafka_connect_oauth_enabled }}"
        oauth_user: "{{ kafka_connect_oauth_user }}"
        oauth_password: "{{ kafka_connect_oauth_password }}"
        ldap_user: "{{ kafka_connect_ldap_user }}"
        ldap_password: "{{ kafka_connect_ldap_password }}"

    - name: Get Connectors on connect cluster1
      uri:
        url: "https://kafka-connect1:8083/connectors"
        status_code: 200
        validate_certs: false
        headers:
          Authorization: "Bearer {{ authorization_token }}"
      register: connectors

    - name: Assert if both ldap user and oauth token works fine
      assert:
        that:
          - connectors.json[0] == connectors1.json[0]
          - connectors.json[1] == connectors1.json[1]
        fail_msg: "Results when using ldap and oauth not same"


    - name: Assert Connector1 Created
      assert:
        that:
          - connectors.json[0] == "sample-connector-1"
        fail_msg: "Connector not created"
        quiet: true

    - name: Wait for Connector tasks to return Running
      uri:
        url: https://kafka-connect1:8083/connectors/sample-connector-1/status
        status_code: 200
        validate_certs: false
        url_username: kafka_connect
        url_password: password
        force_basic_auth: true
      register: connector_status_response
      until: connector_status_response.json.tasks[0].state == 'RUNNING'
      retries: 10
      delay: 5

    - name: Assert Connector2 Created
      assert:
        that:
          - connectors.json[1] == "sample-connector-2"
        fail_msg: "Connector not created"
        quiet: true

    - name: Wait for Connector tasks to return Running
      uri:
        url: https://kafka-connect1:8083/connectors/sample-connector-2/status
        status_code: 200
        validate_certs: false
        url_username: kafka_connect
        url_password: password
        force_basic_auth: true
      register: connector_status_response
      until: connector_status_response.json.tasks[0].state == 'RUNNING'
      retries: 10
      delay: 5

- name: Verify - ksql
  hosts: ksql
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/ksqldb/ksql-server.properties
        property: ssl.truststore.location
        expected_value: /var/ssl/private/ksql.truststore.jks

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/ksqldb/ksql-server.properties
        property: producer.interceptor.classes
        expected_value: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/ksqldb/ksql-server.properties
        property: ksql.schema.registry.basic.auth.user.info
        expected_value: ${securepass:/var/ssl/private/ksql-security.properties:ksql-server.properties/ksql.schema.registry.basic.auth.user.info}

- name: Verify - Callback handler class
  hosts: kafka_broker
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: listener.name.client.plain.sasl.server.callback.handler.class
        expected_value: io.confluent.security.auth.provider.ldap.LdapAuthenticateCallbackHandler

- name: Create LDAP Test User
  hosts: ldap_server
  gather_facts: false
  tasks:
    - include_role:
        name: confluent.test.ldap
        tasks_from: create_user.yml
      vars:
        ldap_user: "testusr"
        ldap_user_uid: "1001"
        ldap_user_gid: "1001"
        ldap_user_password: "test-password"

- name: Create a test kafka.properties that works with LDAP User
  hosts: kafka_broker
  tasks:
    - name: Create properties file
      copy:
        dest: "/tmp/kafka.properties"
        content: |
          sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="testusr" password="test-password";
          sasl.mechanism=PLAIN
          security.protocol=SASL_SSL
          ssl.truststore.location=/var/ssl/private/kafka_broker.truststore.jks
          ssl.truststore.password=truststorepass

- name: Verify - Run kafka topics command against kafka.properties
  hosts: kafka_broker
  gather_facts: false
  tasks:
    - shell: kafka-topics --list --bootstrap-server kafka-broker1:9093 --command-config /tmp/kafka.properties
      register: topic_result
      check_mode: false
      changed_when: false
      failed_when: topic_result.rc != 0
