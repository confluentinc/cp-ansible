---
### Validates TLS version across all components.
### Validates super users are present.
### Validates that secrets protection is masking the correct properties.
### Validates Kafka Connect secrets registry.
### Validates Cluster Registry.
### Validates the filter resolve_principal with different ssl.mapping.rule
### Validates that FIPS is in use in OpenSSL.

- name: Verify - Zookeeper
  hosts: zookeeper
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_tls_version.yml
      vars:
        service_port: 2182
        service_ca: /var/ssl/private/ca.crt
        service_cert: /var/ssl/private/zookeeper.crt
        service_key: /var/ssl/private/zookeeper.key

- name: Verify - kafka_controller
  hosts: kafka_controller
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/controller/server.properties
        property: confluent.metadata.ssl.keystore.location
        expected_value: /var/ssl/private/kafka_controller.keystore.bcfks

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/controller/server.properties
        property: confluent.metadata.ssl.keystore.password
        expected_value: ${securepass:/var/ssl/private/kafka_controller-security.properties:server.properties/confluent.metadata.ssl.keystore.password}

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/controller/server.properties
        property: ssl.truststore.password
        expected_value: ${securepass:/var/ssl/private/kafka_controller-security.properties:server.properties/ssl.truststore.password}

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/controller/server.properties
        property: ssl.principal.mapping.rules
        expected_value: RULE:.*O=(.*?),OU=TEST.*$/$1/

    - name: Get super.users
      shell: grep "super.users" /etc/controller/server.properties
      register: super_users_grep

    - name: Assert super users found in server.properties
      assert:
        that:
          - "'User:CONFLUENT' in super_users_grep.stdout"
        fail_msg: "Super Users property: {{super_users_grep.stdout}} does not contain User:CONFLUENT"

- name: Verify - kafka_broker
  hosts: kafka_broker
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: confluent.metadata.server.ssl.keystore.location
        expected_value: /var/ssl/private/kafka_broker.keystore.bcfks

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: ldap.java.naming.provider.url
        expected_value: ldap://ldap1:389

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: ssl.principal.mapping.rules
        expected_value: RULE:.*O=(.*?),OU=TEST.*$/$1/

    - name: Get super.users
      shell: grep "super.users" /etc/kafka/server.properties
      register: super_users_grep

    - name: Assert super users found in server.properties
      assert:
        that:
          - "'User:dom' in super_users_grep.stdout"
          - "'User:jeff' in super_users_grep.stdout"
          - "'User:CONFLUENT' in super_users_grep.stdout"
        fail_msg: "Super Users property: {{super_users_grep.stdout}} does not contain User:dom and User:jeff"

    - include_role:
        name: confluent.test
        tasks_from: check_tls_version.yml
      vars:
        service_port: "{{item}}"
        service_ca: /var/ssl/private/ca.crt
        service_cert: /var/ssl/private/kafka_broker.crt
        service_key: /var/ssl/private/kafka_broker.key
      loop:
        - 8090
        - 9091
        - 9092
        - 9093

    - name: Test TLS version used in certificate
      shell: openssl s_client -connect {{inventory_hostname}}:9091 </dev/null 2>/dev/null  | grep 'Protocol  :' | sed 's/^.*:\ //'
      register: tls_version

    - fail:
        msg: "TLS version is {{tls_version}}, it should be >=1.2"
      when: tls_version is version('TLSv1.2', '<')

    - name: Check FIPS in OpenSSL
      shell: openssl md5 <<< "123"
      register: openssl_out
      failed_when: openssl_out.rc == 0

- name: Verify - schema_registry
  hosts: schema_registry
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/schema-registry/schema-registry.properties
        property: public.key.path
        expected_value: /var/ssl/private/public.pem

    - import_role:
        name: confluent.test
        tasks_from: check_tls_version.yml
      vars:
        service_port: 8081
        service_ca: /var/ssl/private/ca.crt
        service_cert: /var/ssl/private/schema_registry.crt
        service_key: /var/ssl/private/schema_registry.key

- name: Verify - kafka_rest
  hosts: kafka_rest
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka-rest/kafka-rest.properties
        property: public.key.path
        expected_value: /var/ssl/private/public.pem

    - import_role:
        name: confluent.test
        tasks_from: check_tls_version.yml
      vars:
        service_port: 8082
        service_ca: /var/ssl/private/ca.crt
        service_cert: /var/ssl/private/kafka_rest.crt
        service_key: /var/ssl/private/kafka_rest.key

- name: Verify - kafka_connect
  hosts: kafka_connect
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/connect-distributed.properties
        property: public.key.path
        expected_value: /var/ssl/private/public.pem

    - name: Get Connect Cluster Details
      uri:
        url: https://localhost:8083
        status_code: 200
        validate_certs: false
        url_username: mds
        url_password: password
        client_cert: /var/ssl/private/kafka_connect.crt
        client_key: /var/ssl/private/kafka_connect.key
        force_basic_auth: true
      register: connect_cluster_query

    - set_fact:
        connect_cluster_json: "{{connect_cluster_query.json}}"

    - name: Set kafka_cluster_id Variable
      set_fact:
        kafka_cluster_id: "{{connect_cluster_json.kafka_cluster_id}}"

    - name: Grant role System Admin to mds user on Connect Cluster and Kafka Cluster
      shell: |
        curl -X POST https://kafka-broker1:8090/security/1.0/principals/User:mds/roles/SystemAdmin \
          -u "mds":"password" -H "Content-Type: application/json" \
          --cacert /var/ssl/private/ca.crt --key /var/ssl/private/kafka_connect.key --cert /var/ssl/private/kafka_connect.crt \
          -d '{"clusters":{"kafka-cluster":"{{kafka_cluster_id}}","connect-cluster":"connect-cluster"}}'

    # TODO add another user in molecule.yml and use this user instead of mds
    - name: Create secret
      shell: |
        curl -u mds:password -H 'Content-Type: application/json' \
          --cacert /var/ssl/private/ca.crt --key /var/ssl/private/kafka_connect.key --cert /var/ssl/private/kafka_connect.crt \
          -d '{"secret": "t1"}' -k https://localhost:8083/secret/paths/conn1/keys/topic/versions

    - name: Create test sink file
      shell: |
        touch /tmp/file-sink-test.txt
        chmod 666 /tmp/file-sink-test.txt

    - name: Create connector
      shell: |
        curl -k -X PUT https://localhost:8083/connectors/conn1/config \
          -H "Content-Type: application/json" -u mds:password \
          --cacert /var/ssl/private/ca.crt --key /var/ssl/private/kafka_connect.key --cert /var/ssl/private/kafka_connect.crt \
          -d '{"connector.class": "org.apache.kafka.connect.tools.VerifiableSinkConnector",
          "tasks.max": "1",
          "topics": "${secret:conn1:topic}",
          "file": "/tmp/file-sink-test.txt",
          "principal.service.name": "mds",
          "principal.service.password": "password",
          "consumer.override.security.protocol": "SASL_SSL",
          "consumer.override.sasl.mechanism": "OAUTHBEARER",
          "consumer.override.sasl.login.callback.handler.class": "io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler",
          "consumer.override.bootstrap.servers": "kafka-broker1:9092"}'

    - name: Wait connector status to return 200
      uri:
        url: https://localhost:8083/connectors/conn1/status
        status_code: 200
        client_cert: /var/ssl/private/kafka_connect.crt
        client_key: /var/ssl/private/kafka_connect.key
        ca_path: /var/ssl/private/ca.crt
        validate_certs: false
        url_username: mds
        url_password: password
        force_basic_auth: true
      register: result
      until: result.status == 200
      retries: 10
      delay: 5

    - name: Wait connector status to return Running
      uri:
        url: https://localhost:8083/connectors/conn1/status
        status_code: 200
        validate_certs: false
        url_username: mds
        url_password: password
        client_cert: /var/ssl/private/kafka_connect.crt
        client_key: /var/ssl/private/kafka_connect.key
        ca_path: /var/ssl/private/ca.crt
        force_basic_auth: true
      register: connector_status_response
      until: connector_status_response.json.connector.state == 'RUNNING'
      retries: 10
      delay: 5

    - name: Wait connector tasks to return Running
      uri:
        url: https://localhost:8083/connectors/conn1/status
        status_code: 200
        validate_certs: false
        url_username: mds
        url_password: password
        client_cert: /var/ssl/private/kafka_connect.crt
        client_key: /var/ssl/private/kafka_connect.key
        force_basic_auth: true
      register: connector_status_response
      until: connector_status_response.json.tasks[0].state == 'RUNNING'
      retries: 10
      delay: 5

    - import_role:
        name: confluent.test
        tasks_from: check_tls_version.yml
      vars:
        service_port: 8083
        service_ca: /var/ssl/private/ca.crt
        service_cert: /var/ssl/private/kafka_connect.crt
        service_key: /var/ssl/private/kafka_connect.key

- name: Verify - ksql
  hosts: ksql
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/ksqldb/ksql-server.properties
        property: public.key.path
        expected_value: /var/ssl/private/public.pem

    - import_role:
        name: confluent.test
        tasks_from: check_tls_version.yml
      vars:
        service_port: 8088
        service_ca: /var/ssl/private/ca.crt
        service_cert: /var/ssl/private/kafka_connect.crt
        service_key: /var/ssl/private/kafka_connect.key

- name: Verify - control_center
  hosts: control_center
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/confluent-control-center/control-center-production.properties
        property: public.key.path
        expected_value: /var/ssl/private/public.pem

    - import_role:
        name: confluent.test
        tasks_from: check_tls_version.yml
      vars:
        service_port: 9021
        service_ca: /var/ssl/private/ca.crt
        service_cert: /var/ssl/private/kafka_connect.crt
        service_key: /var/ssl/private/kafka_connect.key

- name: Validate Cluster Registry
  hosts: schema_registry
  gather_facts: false
  vars:
    mds_http_protocol: https
    mds_port: 8090
    mds_super_user: mds
    mds_super_user_password: password
    broker_name: Test-Broker
    connect_name: Test-Connect
    ksql_name: Test-Ksql
    schema_registry_name: Test-Schema
  tasks:
    - name: Retrieve Cluster Registry details
      uri:
        url: "{{mds_http_protocol}}://{{ groups['kafka_broker'][0] }}:{{mds_port}}/security/1.0/registry/clusters"
        method: GET
        validate_certs: false
        force_basic_auth: true
        url_username: "{{mds_super_user}}"
        url_password: "{{mds_super_user_password}}"
        status_code: 200
      register: cluster_name_query

    - set_fact:
        cluster_name_query_json: "{{ cluster_name_query.json }}"

    - name: Assert Broker Cluster ID as expected
      assert:
        that:
          - broker_name == "{{cluster_name_query_json[0]['clusterName']}}"
        fail_msg: "Broker ID set to {{cluster_name_query_json[0]['clusterName']}} not {{broker_name}}"
        quiet: true

    - name: Assert Kafka Connect Cluster ID as expected
      assert:
        that:
          - connect_name == "{{cluster_name_query_json[1]['clusterName']}}"
        fail_msg: "Connect Cluster ID set to {{cluster_name_query_json[1]['clusterName']}} not {{connect_name}}"
        quiet: true

    - name: Assert KSQL Cluster ID as expected
      assert:
        that:
          - ksql_name == "{{cluster_name_query_json[2]['clusterName']}}"
        fail_msg: "KSQL Cluster ID set to {{cluster_name_query_json[2]['clusterName']}} not {{ksql_name}}"
        quiet: true

    - name: Assert Schema Registry Cluster ID as expected
      assert:
        that:
          - schema_registry_name == "{{cluster_name_query_json[3]['clusterName']}}"
        fail_msg: "Schema Registry Cluster ID set to {{cluster_name_query_json[3]['clusterName']}} not {{schema_registry_name}}"
        quiet: true

- name: Validate SSL mapping rule
  hosts: localhost
  gather_facts: false
  tasks:
    - import_role:
        name: variables

    - name: Validate mapping rule with Upper case single match
      assert:
        that:
          - dname == "{{ common_names|confluent.platform.resolve_principal(rules) }}"
      vars:
        rules: "^CN=(.*?), OU=(.*?)$/$1/U,DEFAULT"
        common_names: "CN=kafka-server1, OU=KAFKA"
        dname: KAFKA-SERVER1

    - name: Validate mapping rule with multiple match
      assert:
        that:
          - dname == "{{ common_names|confluent.platform.resolve_principal(rules) }}"
      vars:
        rules: "RULE:^CN=(.*?), OU=(.*?), O=(.*?), L=(.*?), ST=(.*?), C=(.*?)$/$1@$2/"
        common_names: "CN=kafka1, OU=SME, O=mycp, L=Fulton, ST=MD, C=US"
        dname: kafka1@SME

    - name: Validate mapping rule with lowercase single match
      assert:
        that:
          - dname == "{{ common_names|confluent.platform.resolve_principal(rules) }}"
      vars:
        rules: "RULE:^cn=(.*?),ou=(.*?),dc=(.*?),dc=(.*?)$/$1/L"
        common_names: "cn=kafka1,ou=SME,dc=mycp,dc=com"
        dname: kafka1

    - name: Validate multiple mapping rule
      assert:
        that:
          - dname == "{{ common_names|confluent.platform.resolve_principal(rules) }}"
      vars:
        rules: "RULE:^cn=(.*?),ou=(.*?),dc=(.*?),dc=(.*?)$/$1/U,RULE:^CN=(.*?), OU=(.*?), O=(.*?), L=(.*?), ST=(.*?), C=(.*?)$/$1@$2/"
        common_names: "cn=kafka1,ou=SME,dc=mycp,dc=com"
        dname: KAFKA1

    - name: Validate first rule gets applied in case of multiple rule matches
      assert:
        that:
          - dname == "{{ common_names|confluent.platform.resolve_principal(rules) }}"
      vars:
        rules: "RULE:^cn=(.*?),ou=(.*?),dc=(.*?),dc=(.*?)$/$1/U,RULE:^cn=(.*?),ou=(.*?),dc=(.*?),dc=(.*?)$/$1/L"
        common_names: "cn=kafka1,ou=SME,dc=mycp,dc=com"
        dname: KAFKA1

    - name: Validate multiple mapping rule with default
      assert:
        that:
          - dname == "{{ common_names|confluent.platform.resolve_principal(rules) }}"
      vars:
        rules: "RULE:^cn=(.*?),ou=(.*?),dc=(.*?),dc=(.*?)$/$1/L,RULE:^CN=(.*?), OU=(.*?), O=(.*?), L=(.*?), ST=(.*?), C=(.*?)$/$1@$2/,DEFAULT"
        common_names: "cn=kafka1,ou=SME,dc=mycp"
        dname: "cn=kafka1,ou=SME,dc=mycp"
