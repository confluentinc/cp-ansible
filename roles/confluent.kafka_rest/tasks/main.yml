---
- include_role:
    name: confluent.common
  when: not common_role_completed|bool
  tags: common

- name: Gather OS Facts
  setup:
    # Only gathers items in list, filters out the rest
    filter: "{{item}}"
    gather_subset:
      - '!all'
  loop:
    - ansible_os_family
    - ansible_fqdn

- name: Stop Service and Remove Packages on Version Change
  include_role:
    name: confluent.common
    tasks_from: remove_packages.yml
  vars:
    service_name: "{{ kafka_rest_service_name }}"
  when: installation_method == "package"
  tags:
    - package
    - cp_package

- name: Install the Kafka Rest Packages
  yum:
    name: "{{ kafka_rest_packages | product([confluent_package_redhat_suffix]) | map('join') | list }}"
    state: latest
  register: install_kafka_rest_package_result
  until: install_kafka_rest_package_result is success or ansible_check_mode
  retries: 5
  delay: 90
  when:
    - ansible_os_family == "RedHat"
    - installation_method == "package"
  ignore_errors: "{{ ansible_check_mode }}"
  tags:
    - package
    - cp_package
  notify: restart kafka-rest

- name: Install the Kafka Rest Packages
  apt:
    name: "{{ kafka_rest_packages | product([confluent_package_debian_suffix]) | map('join') | list }}"
  register: install_kafka_rest_package_result
  until: install_kafka_rest_package_result is success or ansible_check_mode
  retries: 5
  delay: 90
  when:
    - ansible_os_family == "Debian"
    - installation_method == "package"
  ignore_errors: "{{ ansible_check_mode }}"
  tags:
    - package
    - cp_package
  notify: restart kafka-rest

- name: Create Kafka Rest Group
  group:
    name: "{{kafka_rest_group}}"

- name: Check if Kafka Rest User Exists
  # Create user task must be skipped for non-linux users
  getent:
    database: passwd
    key: "{{kafka_rest_user}}"
  failed_when: false

- name: Create Kafka Rest User
  user:
    name: "{{kafka_rest_user}}"
    comment: Confluent REST proxy
    system: true
    group: "{{kafka_rest_group}}"
  when: (getent_passwd|default({}))[kafka_rest_user] is not defined

# Archive File deployments need to create SystemD service units
# Copy the tarball's systemd service to the system
- name: Copy Kafka Rest Service from archive file to system
  copy:
    src: "{{binary_base_path}}/lib/systemd/system/{{kafka_rest.systemd_file|basename}}"
    remote_src: true
    dest: "{{kafka_rest.systemd_file}}"
    mode: 0644
    force: true
  when: installation_method == "archive"

- include_role:
    name: confluent.ssl
  vars:
    truststore_storepass: "{{kafka_rest_truststore_storepass}}"
    truststore_path: "{{kafka_rest_truststore_path}}"
    keystore_path: "{{kafka_rest_keystore_path}}"
    keystore_storepass: "{{kafka_rest_keystore_storepass}}"
    keystore_keypass: "{{kafka_rest_keystore_keypass}}"
    service_name: kafka_rest
    user: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"
    hostnames: "{{ [inventory_hostname, ansible_fqdn, ansible_host, ansible_ssh_host] | unique }}"
    ca_cert_path: "{{kafka_rest_ca_cert_path}}"
    cert_path: "{{kafka_rest_cert_path}}"
    key_path: "{{kafka_rest_key_path}}"
    export_certs: "{{kafka_rest_export_certs}}"
  when: >
    kafka_rest_ssl_enabled|bool or
    kafka_broker_listeners[kafka_rest_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool or
    mds_tls_enabled | bool
  tags: ssl

- name: Configure Kerberos
  include_role:
    name: confluent.kerberos
  vars:
    kerberos_group: "{{kafka_rest_group}}"
    kerberos_user: "{{kafka_rest_user}}"
    kerberos_keytab_path: "{{kafka_rest_kerberos_keytab_path}}"
    kerberos_keytab_destination_path: "{{kafka_rest_keytab_path}}"
    kerberos_handler: "restart kafka-rest"
  when: kafka_broker_listeners[kafka_rest_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'GSSAPI'

- name: Copy Custom Kafka Rest Files
  include_role:
    name: confluent.common
    tasks_from: copy_files.yml
  vars:
    copy_files: "{{kafka_rest_copy_files}}"
    user: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"
  when: kafka_rest_copy_files | length > 0

- name: Configure RBAC
  include_tasks: rbac.yml
  when: rbac_enabled|bool

- name: Create SSL Certificate Directory
  file:
    path: /var/ssl/private
    state: directory
    mode: 0755
  when: rbac_enabled|bool

- name: Check if MDS public pem file exists on Ansible Controller
  stat:
    path: "{{ token_services_public_pem_file }}"
  register: krest_public_pem_file
  delegate_to: localhost
  vars:
    ansible_connection: local
    ansible_become: "{{ ansible_become_localhost }}"

- name: Debug
  ansible.builtin.debug:
    msg: WARNING - The file {{token_services_public_pem_file}} doesn't exist on the control node
  when: not krest_public_pem_file.stat.exists|bool

- name: Copy in MDS Public Pem File
  copy:
    src: "{{token_services_public_pem_file}}"
    dest: "{{rbac_enabled_public_pem_path}}"
    mode: '755'
    owner: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"
  when:
    - rbac_enabled|bool
    - krest_public_pem_file.stat.exists|bool
  diff: "{{ not mask_sensitive_diff|bool }}"

- name: Create Kafka Rest Config directory
  file:
    path: "{{ kafka_rest.config_file | dirname }}"
    state: directory
    mode: 0750
    owner: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"

- name: Create Kafka Rest Config with Secrets Protection
  include_role:
    name: confluent.common
    tasks_from: secrets_protection.yml
  vars:
    final_properties: "{{ kafka_rest_final_properties }}"
    encrypt_passwords: "{{ kafka_rest_secrets_protection_encrypt_passwords }}"
    encrypt_properties: "{{ kafka_rest_secrets_protection_encrypt_properties }}"
    config_path: "{{ kafka_rest.config_file }}"
    secrets_file: "{{ kafka_rest_secrets_protection_file }}"
    secrets_file_owner: "{{ kafka_rest_user }}"
    secrets_file_group: "{{ kafka_rest_group }}"
    handler: restart kafka-rest
  when: kafka_rest_secrets_protection_enabled|bool

- name: Create Kafka Rest Config
  template:
    src: kafka-rest.properties.j2
    dest: "{{kafka_rest.config_file}}"
    mode: 0640
    owner: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"
  notify: restart kafka-rest
  when: not kafka_rest_secrets_protection_enabled|bool
  diff: "{{ not mask_sensitive_diff|bool }}"

- name: Create Logs Directory
  file:
    path: "{{kafka_rest_log_dir}}"
    state: directory
    owner: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"
    mode: 0770

- name: Update log4j Config for Log Cleanup
  include_role:
    name: confluent.common
    tasks_from: update_log4j.yml
  vars:
    log4j_file: "{{kafka_rest.log4j_file}}"
    log4j_max_backup_index: "{{kafka_rest_max_log_files}}"
    log4j_max_file_size: "{{kafka_rest_log_file_size}}"
    log4j_root_logger: "{{kafka_rest_log4j_root_logger}}"
    handler: "restart kafka-rest"
  when: kafka_rest_custom_log4j|bool

- name: Set Permissions on Log4j Conf
  file:
    path: "{{kafka_rest.log4j_file}}"
    group: "{{kafka_rest_group}}"
    owner: "{{kafka_rest_user}}"
    mode: 0640

- name: Create Kafka Rest Jolokia Config
  template:
    src: kafka_rest_jolokia.properties.j2
    dest: "{{kafka_rest_jolokia_config}}"
    mode: 0640
    owner: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"
  when: kafka_rest_jolokia_enabled|bool
  notify: restart kafka-rest
  diff: "{{ not mask_sensitive_diff|bool }}"

- name: Deploy JMX Exporter Config File
  copy:
    src: "{{kafka_rest_jmxexporter_config_source_path}}"
    dest: "{{kafka_rest_jmxexporter_config_path}}"
    mode: 0640
    owner: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"
  when: kafka_rest_jmxexporter_enabled|bool

- name: Create Service Override Directory
  file:
    path: "{{kafka_rest.systemd_override | dirname }}"
    owner: "{{kafka_rest_user}}"
    group: "{{kafka_rest_group}}"
    state: directory
    mode: 0640

- name: Write Service Overrides
  template:
    src: override.conf.j2
    dest: "{{kafka_rest.systemd_override}}"
    mode: 0640
    owner: root
    group: root
  notify: restart kafka-rest
  diff: "{{ not mask_sensitive_diff|bool }}"

- name: Certs were Updated - Trigger Restart
  command: /bin/true
  notify: restart kafka-rest
  when: certs_updated|bool

- meta: flush_handlers

- name: Start Kafka Rest Service
  systemd:
    name: "{{kafka_rest_service_name}}"
    enabled: true
    state: started

- name: Health Check
  include_tasks: health_check.yml
  when:
    - kafka_rest_health_checks_enabled|bool
    - not ansible_check_mode
  tags: health_check
