---
- include_role:
    name: common
  when: not common_role_completed|bool
  tags: common

- name: Gather OS Facts
  setup:
    # Only gathers items in list, filters out the rest
    filter: "{{item}}"
    gather_subset:
      - '!all'
  loop:
    - ansible_os_family
    - ansible_fqdn

- name: Stop Service and Remove Packages on Version Change
  include_role:
    name: common
    tasks_from: remove_packages.yml
  vars:
    service_name: "{{ kafka_connect_service_name }}"
  when: installation_method == "package"
  tags:
    - package
    - cp_package

- name: Install the Kafka Connect Packages
  yum:
    name: "{{ kafka_connect_packages | product([confluent_package_redhat_suffix]) | map('join') | list }}"
    state: latest
  register: install_kafka_connect_package_result
  until: install_kafka_connect_package_result is success  or ansible_check_mode
  retries: 5
  delay: 90
  when:
    - ansible_os_family == "RedHat"
    - installation_method == "package"
  ignore_errors: "{{ ansible_check_mode }}"
  tags:
    - package
    - cp_package
  notify: restart connect distributed

- name: Install the Kafka Connect Packages
  apt:
    name: "{{ kafka_connect_packages | product([confluent_package_debian_suffix]) | map('join') | list }}"
  register: install_kafka_connect_package_result
  until: install_kafka_connect_package_result is success  or ansible_check_mode
  retries: 5
  delay: 90
  when:
    - ansible_os_family == "Debian"
    - installation_method == "package"
  ignore_errors: "{{ ansible_check_mode }}"
  tags:
    - package
    - cp_package
  notify: restart connect distributed

- name: Create Kafka Connect Group
  group:
    name: "{{kafka_connect_group}}"
  tags:
    - privileged

- name: Check if Kafka Connect User Exists
  # Create user task must be skipped for non-linux users
  getent:
    database: passwd
    key: "{{kafka_connect_user}}"
  failed_when: false

- name: Create Kafka Connect User
  user:
    name: "{{kafka_connect_user}}"
    comment: Confluent Kafka Connect
    system: true
    shell: "{{user_login_shell}}"
    group: "{{kafka_connect_group}}"
  when: (getent_passwd|default({}))[kafka_connect_user] is not defined
  tags:
    - privileged

# Archive File deployments need to create SystemD service units
# Copy the tarball's systemd service to the system
- name: Copy Kafka Connect Service from archive file to system
  copy:
    src: "{{binary_base_path}}/lib/systemd/system/{{kafka_connect_default_service_name}}.service"
    remote_src: true
    dest: "{{kafka_connect.systemd_file}}"
    mode: '644'
    force: true
  when: installation_method == "archive"
  tags:
    - systemd
    - privileged

# Non-Archive File deployments need to create SystemD service units when the user changes the service name
- name: Copy Kafka Connect Service from default install to system
  copy:
    src: "{{systemd_base_dir}}/{{kafka_connect_default_service_name}}.service"
    remote_src: true
    dest: "{{kafka_connect.systemd_file}}"
    mode: '644'
    force: true
  when: installation_method != "archive" and kafka_connect_default_service_name != kafka_connect_service_name
  tags:
    - privileged

- include_role:
    name: ssl
  vars:
    truststore_storepass: "{{kafka_connect_truststore_storepass}}"
    truststore_path: "{{kafka_connect_truststore_path}}"
    keystore_path: "{{kafka_connect_keystore_path}}"
    keystore_storepass: "{{kafka_connect_keystore_storepass}}"
    keystore_keypass: "{{kafka_connect_keystore_keypass}}"
    service_name: "{{ kafka_connect_service_name if kafka_connect_service_name != kafka_connect_default_service_name else 'kafka_connect' }}"
    user: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
    hostnames: "{{ [inventory_hostname, ansible_fqdn, ansible_host, ansible_ssh_host|default(omit), hostname|default(omit)] | unique }}"
    ca_cert_path: "{{kafka_connect_ca_cert_path}}"
    cert_path: "{{kafka_connect_cert_path}}"
    key_path: "{{kafka_connect_key_path}}"
    export_certs: "{{kafka_connect_export_certs}}"
  # CCloud Kafka does not need Keystores/Truststores
  when: >
    kafka_connect_ssl_enabled|bool or
    ( kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool and not public_certificates_enabled|bool ) or
    ( mds_tls_enabled | bool and not public_certificates_enabled|bool ) or
    ( 'schema_registry' in groups and schema_registry_ssl_enabled|bool )
  tags: ssl

- name: Configure Kerberos
  include_role:
    name: kerberos
  vars:
    kerberos_group: "{{kafka_connect_group}}"
    kerberos_user: "{{kafka_connect_user}}"
    kerberos_keytab_path: "{{kafka_connect_kerberos_keytab_path}}"
    kerberos_keytab_destination_path: "{{kafka_connect_keytab_path}}"
    kerberos_handler: "restart connect distributed"
  when: "'GSSAPI' in (kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | confluent.platform.normalize_sasl_protocol)"


- name: Copy Custom Files From All Components List
  include_role:
    name: common
    tasks_from: copy_files.yml
  vars:
    copy_files: "{{all_components_copy_files}}"
    user: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
  when: all_components_copy_files | length > 0
  tags:
    - configuration

- name: Extract Connect Principal from cert
  import_role:
    name: common
    tasks_from: cert_principal_extract.yml
  vars:
    keystore_path: "{{kafka_connect_keystore_path}}"
    keystore_storepass: "{{kafka_connect_keystore_storepass}}"
    pm_rules: "{{kafka_connect_final_properties.get('auth.ssl.principal.mapping.rules','DEFAULT')}}"
  when:
    - rbac_enabled|bool
    - mds_ssl_client_authentication != 'none'

- name: Configure RBAC for mTLS User
  include_tasks: rbac.yml
  vars:
    connect_user: "{{ ks_extracted_principal | urlencode }}"
  when:
    - rbac_enabled|bool
    - mds_ssl_client_authentication != 'none'

- name: Configure RBAC for OAuth User
  include_tasks: rbac.yml
  vars:
    connect_user: "{{kafka_connect_oauth_principal}}"
  when: rbac_enabled|bool and oauth_enabled|bool

- name: Configure RBAC for Ldap User
  include_tasks: rbac.yml
  vars:
    connect_user: "{{kafka_connect_ldap_user}}"
  when:
    - rbac_enabled|bool
    - "'ldap' in auth_mode"

- name: Import IDP certificate to Truststore for OAuth
  include_role:
    name: common
    tasks_from: idp_certs.yml
  vars:
    idp_cert_path: "{{ oauth_idp_cert_path }}"
    idp_cert_dest: /tmp/oauth_idp_cert.pem
    alias: "oauth_cert"
    truststore_storepass: "{{kafka_connect_truststore_storepass}}"
    truststore_path: "{{kafka_connect_truststore_path}}"
    create_bouncy_castle_keystore: false
    restart_handler_name: "restart connect distributed"
  when:
    - oauth_enabled|bool or schema_registry_oauth_enabled|bool or kafka_rest_oauth_enabled|bool or kafka_connect_oauth_enabled|bool or kafka_connect_replicator_oauth_enabled|bool
    - oauth_idp_cert_path != ""

- name: Create Kafka Connect Config directory
  file:
    path: "{{ kafka_connect.config_file | dirname }}"
    state: directory
    mode: '750'
    owner: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
  tags:
    - filesystem

- name: Copy client assertion files
  include_role:
    name: common
    tasks_from: copy_client_assertion_files.yml
  vars:
    user: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
    client_assertion_files:
      - src: "{{ kafka_connect_oauth_client_assertion_private_key_file }}"
        dest: "{{ kafka_connect_oauth_client_assertion_private_key_file_dest_path }}"
      - src: "{{ kafka_connect_oauth_client_assertion_template_file }}"
        dest: "{{ kafka_connect_oauth_client_assertion_template_file_dest_path }}"
  tags:
    - configuration

- name: Create Kafka Connect Config
  template:
    src: connect-distributed.properties.j2
    dest: "{{kafka_connect.config_file}}"
    mode: '640'
    owner: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
  notify: restart connect distributed
  diff: "{{ not mask_sensitive_diff|bool }}"
  tags:
    - configuration

- name: Create Kafka Connect Config with Secrets Protection
  include_role:
    name: common
    tasks_from: secrets_protection.yml
  vars:
    final_properties: "{{ kafka_connect_final_properties }}"
    encrypt_passwords: "{{ kafka_connect_secrets_protection_encrypt_passwords }}"
    encrypt_properties: "{{ kafka_connect_secrets_protection_encrypt_properties }}"
    config_path: "{{ kafka_connect.config_file }}"
    secrets_file: "{{ kafka_connect_secrets_protection_file }}"
    secrets_file_owner: "{{ kafka_connect_user }}"
    secrets_file_group: "{{ kafka_connect_group }}"
    ca_cert_path: "{{ kafka_connect_ca_cert_path if kafka_connect_ssl_enabled|bool else '' }}"
    handler: restart connect distributed
  tags:
    - configuration
  when:
    - kafka_connect_secrets_protection_enabled|bool
    - rbac_enabled|bool or confluent_cli_version is version('3.0.0', '>=')

- name: Install Connect Plugins
  include_tasks: connect_plugins.yml

- name: Copy Kafka Connect Files
  include_role:
    name: common
    tasks_from: copy_files.yml
  vars:
    copy_files: "{{kafka_connect_copy_files}}"
    user: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
  when: kafka_connect_copy_files | length > 0
  tags:
    - configuration

- name: Create Logs Directory
  file:
    path: "{{kafka_connect_log_dir}}"
    state: directory
    group: "{{kafka_connect_group}}"
    owner: "{{kafka_connect_user}}"
    mode: '770'
  tags:
    - filesystem
    - log

- name: Create logredactor rule file directory
  file:
    path: "{{ logredactor_rule_path | dirname }}"
    state: directory
    mode: '755'
  when: (kafka_connect_custom_log4j2|bool) and (logredactor_enabled|bool) and (logredactor_rule_url == '')
  tags:
    - log

- name: Copy logredactor rule file from control node to component node
  copy:
    src: "{{ logredactor_rule_path_local }}"
    dest: "{{ logredactor_rule_path }}"
    mode: '644'
  when: (kafka_connect_custom_log4j2|bool) and (logredactor_enabled|bool) and (logredactor_rule_url == '')
  tags:
    - log

- name: Check if Connect log4j file exists
  stat:
    path: "{{ kafka_connect.log4j_file }}"
  register: log4j_file_stat
  tags:
    - log

- name: Backup Connect log4j file if it exists
  copy:
    src: "{{ kafka_connect.log4j_file }}"
    dest: "{{ kafka_connect.log4j_file }}.bak"
    remote_src: true
    mode: '644'
  when: log4j_file_stat.stat.exists
  tags:
    - log

- name: Update log4j Config for Log Cleanup
  confluent.platform.update_log4j2:
    path: "{{kafka_connect.log4j_file}}"
    max: "{{kafka_connect_max_log_files}}"
    size: "{{kafka_connect_log_file_size}}"
    root_level: "{{kafka_connect_log4j2_root_logger_level}}"
    root_appenders: "{{ kafka_connect_log4j2_root_appenders }}"
    add_redactor: "{{ logredactor_enabled|bool }}"
    redactor_refs: "{{ kafka_connect_logredactor_logger_specs_list | map(attribute='appenderRefs') | list }}"
    redactor_rules: "{{ (logredactor_rule_url == '') | ternary(logredactor_rule_path, logredactor_rule_url) }}"
    redactor_policy_refresh_interval: "{{ logredactor_policy_refresh_interval }}"
    redactor_logger_names: "{{ kafka_connect_logredactor_logger_specs_list | map(attribute='logger_name') | list }}"
  notify: restart connect distributed
  when: kafka_connect_custom_log4j2|bool
  tags:
    - configuration
    - log

- name: Set Permissions on Log4j Conf
  file:
    path: "{{kafka_connect.log4j_file}}"
    group: "{{kafka_connect_group}}"
    owner: "{{kafka_connect_user}}"
    mode: '640'
  tags:
    - filesystem
    - log

- name: Restart kafka connect
  ansible.builtin.debug:
    msg: "restarting kafka connect"
  notify: restart connect distributed
  when: (kafka_connect_custom_log4j2|bool) and (logredactor_enabled|bool) and (not kafka_connect_skip_restarts|bool)
  tags:
    - log

- name: Create Kafka Connect Jolokia Config
  template:
    src: kafka_connect_jolokia.properties.j2
    dest: "{{kafka_connect_jolokia_config}}"
    mode: '640'
    owner: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
  when: kafka_connect_jolokia_enabled|bool
  notify: restart connect distributed
  diff: "{{ not mask_sensitive_diff|bool }}"
  tags:
    - configuration

- name: Deploy JMX Exporter Config File
  copy:
    src: "{{kafka_connect_jmxexporter_config_source_path}}"
    dest: "{{kafka_connect_jmxexporter_config_path}}"
    mode: '640'
    owner: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
  when: kafka_connect_jmxexporter_enabled|bool
  tags:
    - configuration

- name: Create Basic Auth Jaas File
  template:
    src: jaas.conf.j2
    dest: "{{kafka_connect.jaas_file}}"
    mode: '640'
    owner: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
  notify: restart connect distributed
  when: kafka_connect_authentication_type == 'basic'

- name: Create Basic Auth Password File
  template:
    src: password.properties.j2
    dest: "{{kafka_connect.password_file}}"
    mode: '640'
    owner: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
  notify: restart connect distributed
  when: kafka_connect_authentication_type == 'basic'

- name: Create Service Override Directory
  file:
    path: "{{kafka_connect.systemd_override | dirname}}"
    owner: "{{kafka_connect_user}}"
    group: "{{kafka_connect_group}}"
    state: directory
    mode: '750'
  tags:
    - systemd
    - privileged

- name: Write Service Overrides
  template:
    src: override.conf.j2
    dest: "{{ kafka_connect.systemd_override }}"
    mode: '640'
    owner: root
    group: root
  notify: restart connect distributed
  diff: "{{ not mask_sensitive_diff|bool }}"
  tags:
    - systemd
    - privileged

- name: Certs were Updated - Trigger Restart
  command: /bin/true
  notify: restart connect distributed
  changed_when: false
  when: certs_updated|bool

- meta: flush_handlers

- name: Start Connect Service
  systemd:
    name: "{{kafka_connect_service_name}}"
    enabled: true
    state: started
  tags:
    - systemd

- name: Health Check
  include_tasks: health_check.yml
  when:
    - kafka_connect_health_checks_enabled|bool
    - not ansible_check_mode
  tags: health_check

# Set a host fact with the direct cluster parent group
# Host of the same cluster have the same group.id
- name: Set parent Cluster
  vars:
    keywords:
      - kafka_connect
      - kafka_connect_parallel
      - kafka_connect_serial
      - kafka_broker
      - kafka_broker_parallel
      - kafka_broker_serial
      - kafka_rest
      - kafka_rest_parallel
      - kafka_rest_serial
      - control_center_next_gen
      - control_center_next_gen_parallel
      - control_center_next_gen_serial
      - ksql
      - ksql_parallel
      - ksql_serial
      - schema_registry
      - kafka_controller
      - kafka_controller_parallel
      - kafka_controller_serial
  set_fact:
    parent_kafka_connect_cluster_group: "{{ (group_names | difference(keywords))[0] | default('kafka_connect') }}"
    parent_kafka_connect_cluster_id: "{{ kafka_connect_final_properties['group.id'] }}"

- name: Register Cluster
  include_tasks: register_cluster.yml
  run_once: true

- name: Deploy Connectors
  include_tasks: deploy_connectors.yml

- name: Delete temporary keys/certs when keystore and trustore is provided
  file:
    path: "{{item}}"
    state: absent
  loop:
    - "{{kafka_connect_ca_cert_path}}"
    - "{{kafka_connect_cert_path}}"
    - "{{kafka_connect_key_path}}"
  when: (ssl_provided_keystore_and_truststore | bool)
