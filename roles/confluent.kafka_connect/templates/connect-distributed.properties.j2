# Maintained by Ansible

{% for key, value in kafka_connect.properties.items() %}
{{key}}={{value}}
{% endfor %}

# Kafka Connect Configuration
listeners={{kafka_connect_http_protocol}}://0.0.0.0:{{kafka_connect_rest_port}}
rest.advertised.listener={{kafka_connect_http_protocol}}
rest.advertised.host.name={{inventory_hostname}}
rest.advertised.host.port={{kafka_connect_rest_port}}
{% if kafka_connect_ssl_enabled|bool %}
listeners.{{kafka_connect_http_protocol|lower}}.ssl.keystore.location={{kafka_connect_keystore_path}}
listeners.{{kafka_connect_http_protocol|lower}}.ssl.keystore.password={{kafka_connect_keystore_storepass}}
listeners.{{kafka_connect_http_protocol|lower}}.ssl.key.password={{kafka_connect_keystore_keypass}}
{% if kafka_connect_ssl_mutual_auth_enabled|bool %}
listeners.{{kafka_connect_http_protocol|lower}}.ssl.client.auth=false
listeners.{{kafka_connect_http_protocol|lower}}.ssl.truststore.location={{kafka_connect_truststore_path}}
listeners.{{kafka_connect_http_protocol|lower}}.ssl.truststore.password={{kafka_connect_truststore_storepass}}
{% endif %}
{% endif %}

# Kafka Broker Configuration
bootstrap.servers={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{kafka_broker_listeners[kafka_connect_kafka_listener_name]['port']}}{% endfor %}

security.protocol={{kafka_broker_listeners[kafka_connect_kafka_listener_name] | kafka_protocol_defaults(sasl_protocol, ssl_enabled) }}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool %}
ssl.truststore.location={{kafka_connect_truststore_path}}
ssl.truststore.password={{kafka_connect_truststore_storepass}}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_mutual_auth_enabled'] | default(ssl_mutual_auth_enabled) | bool %}
ssl.keystore.location={{kafka_connect_keystore_path}}
ssl.keystore.password={{kafka_connect_keystore_storepass}}
ssl.key.password={{kafka_connect_keystore_keypass}}
{% endif %}
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'PLAIN' %}
sasl.mechanism=PLAIN
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
   username="{{sasl_plain_users.kafka_connect.principal}}" password="{{sasl_plain_users.kafka_connect.password}}";
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'GSSAPI' %}
sasl.mechanism=GSSAPI
sasl.kerberos.service.name={{kerberos_kafka_broker_primary}}
sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
   useKeyTab=true \
   storeKey=true \
   keyTab="{{kerberos.keytab_dir}}/{{kafka_connect_kerberos_keytab_path | basename}}" \
   principal="{{kafka_connect_kerberos_principal}}";
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'SCRAM-SHA-256' %}
sasl.mechanism=SCRAM-SHA-256
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="{{sasl_scram_users.kafka_connect.principal}}" password="{{sasl_scram_users.kafka_connect.password}}";
{% endif %}


{% set schema_registries = groups.get('schema_registry', []) %}
{% if schema_registries %}
value.converter.schema.registry.url={% for host in groups['schema_registry'] %}{% if loop.index > 1%},{% endif %}{{ schema_registry_http_protocol }}://{{ host }}:{{ schema_registry_listener_port }}{% endfor %}

key.converter.schema.registry.url={% for host in groups['schema_registry'] %}{% if loop.index > 1%},{% endif %}{{ schema_registry_http_protocol }}://{{ host }}:{{ schema_registry_listener_port }}{% endfor %}

{% endif %}

# Connect Producer Configuration
producer.bootstrap.servers={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{kafka_broker_listeners[kafka_connect_kafka_listener_name]['port']}}{% endfor %}

producer.security.protocol={{kafka_broker_listeners[kafka_connect_kafka_listener_name] | kafka_protocol_defaults(sasl_protocol, ssl_enabled) }}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool %}
producer.ssl.truststore.location={{kafka_connect_truststore_path}}
producer.ssl.truststore.password={{kafka_connect_truststore_storepass}}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_mutual_auth_enabled'] | default(ssl_mutual_auth_enabled) | bool %}
producer.ssl.keystore.location={{kafka_connect_keystore_path}}
producer.ssl.keystore.password={{kafka_connect_keystore_storepass}}
producer.ssl.key.password={{kafka_connect_keystore_keypass}}
{% endif %}
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'PLAIN' %}
producer.sasl.mechanism=PLAIN
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'GSSAPI' %}
producer.sasl.mechanism=GSSAPI
producer.sasl.kerberos.service.name={{kerberos_kafka_broker_primary}}
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'SCRAM-SHA-256' %}
producer.sasl.mechanism=SCRAM-SHA-256
{% endif %}

# Connect Consumer Configuration
consumer.bootstrap.servers={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{kafka_broker_listeners[kafka_connect_kafka_listener_name]['port']}}{% endfor %}

consumer.security.protocol={{kafka_broker_listeners[kafka_connect_kafka_listener_name] | kafka_protocol_defaults(sasl_protocol, ssl_enabled) }}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool %}
consumer.ssl.truststore.location={{kafka_connect_truststore_path}}
consumer.ssl.truststore.password={{kafka_connect_truststore_storepass}}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_mutual_auth_enabled'] | default(ssl_mutual_auth_enabled) | bool %}
consumer.ssl.keystore.location={{kafka_connect_keystore_path}}
consumer.ssl.keystore.password={{kafka_connect_keystore_storepass}}
consumer.ssl.key.password={{kafka_connect_keystore_keypass}}
{% endif %}
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'PLAIN' %}
consumer.sasl.mechanism=PLAIN
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'GSSAPI' %}
consumer.sasl.mechanism=GSSAPI
consumer.sasl.kerberos.service.name={{kerberos_kafka_broker_primary}}
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'SCRAM-SHA-256' %}
consumer.sasl.mechanism=SCRAM-SHA-256
{% endif %}

# Producer Monitoring Configuration
producer.confluent.monitoring.interceptor.bootstrap.servers={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{kafka_broker_listeners[kafka_connect_kafka_listener_name]['port']}}{% endfor %}

producer.confluent.monitoring.interceptor.security.protocol={{kafka_broker_listeners[kafka_connect_kafka_listener_name] | kafka_protocol_defaults(sasl_protocol, ssl_enabled) }}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool %}
producer.confluent.monitoring.interceptor.ssl.truststore.location={{kafka_connect_truststore_path}}
producer.confluent.monitoring.interceptor.ssl.truststore.password={{kafka_connect_truststore_storepass}}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_mutual_auth_enabled'] | default(ssl_mutual_auth_enabled) | bool %}
producer.confluent.monitoring.interceptor.ssl.keystore.location={{kafka_connect_keystore_path}}
producer.confluent.monitoring.interceptor.ssl.keystore.password={{kafka_connect_keystore_storepass}}
producer.confluent.monitoring.interceptor.ssl.key.password={{kafka_connect_keystore_keypass}}
{% endif %}
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'PLAIN' %}
producer.confluent.monitoring.interceptor.sasl.mechanism=PLAIN
producer.confluent.monitoring.interceptor.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
   username="{{sasl_plain_users.kafka_connect.principal}}" password="{{sasl_plain_users.kafka_connect.password}}";
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'GSSAPI' %}
producer.confluent.monitoring.interceptor.sasl.mechanism=GSSAPI
producer.confluent.monitoring.interceptor.sasl.kerberos.service.name={{kerberos_kafka_broker_primary}}
producer.confluent.monitoring.interceptor.sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
   useKeyTab=true \
   storeKey=true \
   keyTab="{{kerberos.keytab_dir}}/{{kafka_connect_kerberos_keytab_path | basename}}" \
   principal="{{kafka_connect_kerberos_principal}}";
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'SCRAM-SHA-256' %}
producer.confluent.monitoring.interceptor.sasl.mechanism=SCRAM-SHA-256
producer.confluent.monitoring.interceptor.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="{{sasl_scram_users.kafka_connect.principal}}" password="{{sasl_scram_users.kafka_connect.password}}";
{% endif %}

# Consumer Monitoring Configuration
consumer.confluent.monitoring.interceptor.bootstrap.servers={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:{{kafka_broker_listeners[kafka_connect_kafka_listener_name]['port']}}{% endfor %}

consumer.confluent.monitoring.interceptor.security.protocol={{kafka_broker_listeners[kafka_connect_kafka_listener_name] | kafka_protocol_defaults(sasl_protocol, ssl_enabled) }}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool %}
consumer.confluent.monitoring.interceptor.ssl.truststore.location={{kafka_connect_truststore_path}}
consumer.confluent.monitoring.interceptor.ssl.truststore.password={{kafka_connect_truststore_storepass}}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_mutual_auth_enabled'] | default(ssl_mutual_auth_enabled) | bool %}
consumer.confluent.monitoring.interceptor.ssl.keystore.location={{kafka_connect_keystore_path}}
consumer.confluent.monitoring.interceptor.ssl.keystore.password={{kafka_connect_keystore_storepass}}
consumer.confluent.monitoring.interceptor.ssl.key.password={{kafka_connect_keystore_keypass}}
{% endif %}
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'PLAIN' %}
consumer.confluent.monitoring.interceptor.sasl.mechanism=PLAIN
consumer.confluent.monitoring.interceptor.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
   username="{{sasl_plain_users.kafka_connect.principal}}" password="{{sasl_plain_users.kafka_connect.password}}";
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'GSSAPI' %}
consumer.confluent.monitoring.interceptor.sasl.mechanism=GSSAPI
consumer.confluent.monitoring.interceptor.sasl.kerberos.service.name={{kerberos_kafka_broker_primary}}
consumer.confluent.monitoring.interceptor.sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
   useKeyTab=true \
   storeKey=true \
   keyTab="{{kerberos.keytab_dir}}/{{kafka_connect_kerberos_keytab_path | basename}}" \
   principal="{{kafka_connect_kerberos_principal}}";
{% endif %}
{% if kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'SCRAM-SHA-256' %}
consumer.confluent.monitoring.interceptor.sasl.mechanism=SCRAM-SHA-256
consumer.confluent.monitoring.interceptor.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
   username="{{sasl_scram_users.kafka_connect.principal}}" password="{{sasl_scram_users.kafka_connect.password}}";
{% endif %}

{% if rbac_enabled|bool %}
###################### REST extensions: RBAC and Secret Registry ######################
rest.extension.classes=io.confluent.connect.security.ConnectSecurityExtension,io.confluent.connect.secretregistry.ConnectSecretRegistryExtension
# rest.extension.classes=io.confluent.connect.security.ConnectSecurityExtension


# Connect Secret Registry to Kafka
config.providers.secret.param.kafkastore.bootstrap.servers={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:9093{% endfor %}
config.providers.secret.param.kafkastore.security.protocol=SASL_SSL

# SASL/OAUTHBEARER
config.providers.secret.param.kafkastore.sasl.mechanism=OAUTHBEARER
config.providers.secret.param.kafkastore.sasl.login.callback.handler.class=io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
config.providers.secret.param.kafkastore.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
    username="{{rbac_connect_user}}" \
    password="{{rbac_connect_user_password}}" \
    metadataServerUrls={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}{{ host }}:8090{% endfor %};

# truststore
config.providers.secret.param.kafkastore.ssl.truststore.location=/var/ssl/private/client.truststore.jks
config.providers.secret.param.kafkastore.ssl.truststore.password=confluent

#keystore
config.providers.secret.param.kafkastore.ssl.keystore.location=/var/ssl/private/connect.keystore.jks
config.providers.secret.param.kafkastore.ssl.keystore.password=confluent
config.providers.secret.param.kafkastore.ssl.key.password=confluent

config.providers.secret.param.kafkastore.ssl.client.auth=true
config.providers.secret.param.kafkastore.ssl.endpoint.identification.algorithm=HTTPS


##################### RBAC #####################
### Authentication
rest.servlet.initializor.classes=io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler

# The path to a directory containing public keys that should be used to verify json web tokens
# during authentication
public.key.path="{{rbac_enabled_public_pem_path}}{{rbac_mtls_public_pem_name}}"

# location of metadata service
# For SSL settings connect will use top level ssl.* configs
confluent.metadata.bootstrap.server.urls={% for host in groups['kafka_broker'] %}{% if loop.index > 1%},{% endif %}http://{{ host }}:8090{% endfor %}

# credentials to use with MDS
{% if rbac_enabled|bool and ssl_enabled|bool %}
confluent.metadata.basic.auth.user.info={{ inventory_hostname }}:{{ rbac_mtls_principal_password }}
{% endif %}
{% if rbac_enabled|bool and ssl_enabled|bool and ssl_custom_certs|bool %}
confluent.metadata.basic.auth.user.info={{ rbac_mtls_principal_name }}:{{ rbac_mtls_principal_password }}
{% endif %}
confluent.metadata.http.auth.credentials.provider=BASIC


####### SSL for MDS ########
# Also inherited from top level configs
# confluent.metadata.ssl.truststore.location=/var/ssl/private/client.truststore.jks
# confluent.metadata.ssl.truststore.password=confluent
# confluent.metadata.ssl.keystore.location=/var/ssl/private/connect.keystore.jks
# confluent.metadata.ssl.keystore.password=confluent
# confluent.metadata.ssl.key.password=confluent
{% endif %}